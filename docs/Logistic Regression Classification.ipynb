{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Derivation, intuition, and a basic implementation of a logistic regression classifier in the Julia language."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Motivation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we're interested in taking the values of a set of predictor variables to decide between two categories.<br>\n",
      "\n",
      "For example suppose we're amateur meteorologists and we have data to predict:<br>\n",
      "$(\\text{cloudy}=0.5, \\text{temperature}=90, \\text{time_of_day}=5) \\rightarrow \\text{rain}$ or $\\text{no rain}?$<br>\n",
      "\n",
      "Or we're wall-street amateurs and we want to predict:<br>\n",
      "$(\\text{company_quarterly_profits}=\\$0.2, \\text{company_popularity}=0.01, \\text{age_of_company}=10\\text{yr}) \\rightarrow \\text{buy stock}$ or $\\text{don't buy stock}?$<br>\n",
      "\n",
      "<br>\n",
      "\n",
      "I.e. we have two discrete choices and some training data mapping feature values to categories.<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Definitions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More formally, suppose we have:<br>\n",
      "A set of $m$ training examples $T = \\{(\\vec{x_{i}}, y_i)\\}$ for $0 \\leq i \\leq m - 1$<br>\n",
      "where $\\vec{x_{i}} \\in \\mathbb{R}^n$ is the $i^\\text{th}$ training example input, and $n$ is the number of features, $y_i \\in \\mathbb{R}$ is $i^\\text{th}$ is the training output, and $y_i \\in \\{0, 1\\}$.<br>\n",
      "and we let $x_{i,j}$ denote the $j^\\text{th}$ feature of the $i^\\text{th}$ training example.<br>\n",
      "\n",
      "In <b>logistic regression</b> classification is approached by thresholding the hypothesis function $h_\\vec{\\theta} : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ defined by:<br>\n",
      "$$h_\\vec{\\theta}(\\vec{x}) = \\frac{1}{1 + \\mathbb{e}^{-\\vec{\\theta}^T \\vec{x}}}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}