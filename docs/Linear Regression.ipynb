{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Describing and implementing multivariate linear regression in Julia.<br><br>\n",
      "Definitions:<br>\n",
      "Let the set of $m$ training examples be $T = \\{(\\vec{x_{i}}, y_i)\\}$ for $0 \\leq i \\leq m - 1$<br>\n",
      "where $\\vec{x_{i}} \\in \\mathbb{R}^n$ is the $i^\\text{th}$ training example input, and $n$ is the number of features, $y_i \\in \\mathbb{R}$ is $i^\\text{th}$ is the training output.<br>\n",
      "Let $x_{i,j}$ denote the $j^\\text{th}$ feature of the $i^\\text{th}$ training example.<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The linear regression hypothesis function $h_\\vec{\\theta} : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ has form:<br>\n",
      "$$h_\\vec{\\theta}(\\vec{x}) = \\sum_{i=0}^{n} \\theta_{i} x_{i} = \\vec{\\theta}^{T} \\vec{x}$$\n",
      "Where we take $x_0 = 1$, and let $\\vec{\\theta} \\in \\mathbb{R}^{n+1}$ be the parameter vector.<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The cost function $J : \\mathbb{R}^{n+1} \\rightarrow \\mathbb{R}$ has form:<br>\n",
      "$$J(\\vec{\\theta}) = \\frac{1}{2 m}\\sum_{i=1}^{m}(h_\\vec{\\theta}(\\vec{x}_{i}) - y_i)^2 = \\frac{1}{2 m}\\sum_{i=1}^{m}(\\vec{\\theta}^{T} \\vec{x} - y_i)^2$$<br>\n",
      "\n",
      "We want to minimize the cost function $J$ by varying the parameter vector $\\vec{\\theta}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, we can analytically solve this problem by solving the system of equations for $(\\theta_0, \\theta_1, \\dotsc, \\theta_{n})^T$ given by $\\frac{\\partial}{\\partial \\theta_i}{J(\\vec{\\theta})} = 0$ for all $i \\in \\{0,1,...,n\\}$.<br>\n",
      "\n",
      "\n",
      "We can alternatively use an optimization algorithm like gradient descent, and we can recycle it for other min/max problems; so I'll go over that."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Gradient Descent"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One method to find the parameter vector is the gradient descent algorithm.<br><br>\n",
      "\n",
      "The idea in gradient descent is similar to the idea in single variable calculus:<br>\n",
      "<img src=\"files/images/deriv.png\"><br>\n",
      "Where we know that $\\frac{d}{dx} f(x) = 0$ at the extrema (points A and B), and $\\frac{d}{dx} f(x)$ can otherwise be used direct us toward the nearest (local) minimum/maximum (e.g. the slope of the lines at points C, D, E, F).<br><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a multivariate function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$, we use the vector differential, or gradient: $\\vec{\\nabla} f(x)$ to guide us to a minimum.<br>For example, in:\n",
      "<img src=\"files/images/gradient.png\" width=\"400px\"><br>\n",
      "A gradient vector field is shown projected beneath a plot of the function $f(x,y) = \u2212(\\cos^2 x + \\cos^2 y)^2.$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the vectors are pointed to the direction of maximum ascent--i.e. away from the minimum, thus if we want to minimize our cost function $J$ in the linear regression problem, we need to look toward the opposite direction: $-\\vec{\\nabla} f(x)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see how we actually follow that direction, consider the Taylor expansion of $f(\\vec{x}_0 + h\\vec{\\epsilon})$ where $\\epsilon \\in \\mathbb{R}^{n+1}$ is a unit-vector that we want to minimize in the direction of if we start at vector $\\vec{x}_0$, and $h \\in \\mathbb{R}$ is a constant \"step-size\":<br>\n",
      "$$\n",
      "f(\\vec{x}_0 + h\\vec{\\epsilon}) = f(\\vec{x}_0) + h\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon} + h^2\\text{(const. error)}\n",
      "$$\n",
      "<br><br>\n",
      "If we take $h$ to be very small such that $h^2$ is even smaller, then let's regard $h^2\\text{(const. error)} \\approx 0$ so that:\n",
      "$$\n",
      "f(\\vec{x}_0 + h\\vec{\\epsilon}) \\approx f(\\vec{x}_0) + h\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to choose a vector $\\vec{\\epsilon}$ that minimizes $f(\\vec{x}_0 + h\\vec{\\epsilon})$.<br>\n",
      "i.e. that minimizes\n",
      "$f(\\vec{x}_0) + h\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon}$.<br><br>\n",
      "\n",
      "Note that $\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon} = \\lvert \\vec{\\nabla} f(\\vec{x}_0) \\rvert \\lvert \\vec{\\epsilon} \\rvert \\cos \\delta$ where $\\delta$ is the angle between $\\vec{\\nabla} f(\\vec{x}_0)$ and $\\vec{\\epsilon}$.<br>\n",
      "By choosing unit-vector $\\vec{\\epsilon} = \\frac{-\\vec{\\nabla} f(\\vec{x}_0)}{\\lvert \\vec{\\nabla} f(\\vec{x}_0) \\rvert}$, we have $\\cos(\\delta) = -1$, its least value. <br><br>\n",
      "\n",
      "So taking:\n",
      "$\\vec{x_1} = \\vec{x}_0 + h\\vec{\\epsilon} = \\vec{x}_0 - h\\vec{\\nabla} f(\\vec{x}_0)$ for some step-size $h$,<br>\n",
      "and inspecting whether $f(\\vec{x_{i+1}}) - f(\\vec{x_{i}})$ reaches convergence within some threshold, we have the basic gradient descent algorithm.<br><br>\n",
      "\n",
      "To implement it with our cost function, we need the $i^\\text{th}$ component of $\\vec{\\nabla}J(\\vec{\\theta})$.<br>\n",
      "This is given by:  $\\frac{\\partial}{\\partial \\theta_i} J(\\vec{\\theta}) = \\frac{1}{m} \\sum_{j=1}^{m}x_{j,i}(\\vec{\\theta}^T \\cdot \\vec{x}_j - y_j)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also see: http://mathworld.wolfram.com/MethodofSteepestDescent.html <br>\n",
      "\n",
      "Image sources:<br>\n",
      "http://www.themathpage.com/acalc/calc_IMG/060.png<br>\n",
      "http://en.wikipedia.org/wiki/File:Gradient99.png<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Metaprogramming and DataFrames Formulas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Julia has \"metaprogramming\" support: http://docs.julialang.org/en/latest/manual/metaprogramming/<br>\n",
      "\n",
      "The DataFrames package provides a \"Formula\" object for use in regression modeling: <a href=\"https://github.com/JuliaStats/DataFrames.jl/blob/f9556c023db999db39f85261698d5edde4089159/doc/sections/09_formulas.md\">DataFrames.Formula</a><br>\n",
      "\n",
      "The syntax of formulae seems similar to that of <a href=\"http://science.nature.nps.gov/im/datamgmt/statistics/r/formulas/\">R formulae</a>, which is in turn derived from the \"S\" language:<br>\n",
      "<p>\n",
      "<b>Chambers and Hastie (1993) \"Statistical Models in S\" is the definitive reference for formulas in S and thus R, although their conception of formulas has been extended for other uses, and there is a package \"formula\" that defines a new object class Formula that inherits from class formula. At the R command line, ?formula will give you some details.</b><br>\n",
      "\n",
      "The design notes describe the language of the formulas:\n",
      "<a href=\"https://github.com/JuliaStats/DataFrames.jl/blob/f9556c023db999db39f85261698d5edde4089159/doc/other/03_design_details.md\n",
      "\">Design Notes</a><br>\n",
      "And we can just look at the source: https://github.com/JuliaStats/DataFrames.jl/blob/master/src/formula.jl"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using DataFrames\n",
      "using RDatasets\n",
      "\n",
      "iris = data(\"datasets\", \"iris\")\n",
      "# The DataFrames formula parser seems to take issue with column names having periods\n",
      "# and I don't know if there's some proper way to escape them--so I'll just rename them:\n",
      "# Uses string.replace: https://github.com/JuliaLang/julia/blob/master/base/string.jl\n",
      "# and dataframe.rename: https://github.com/JuliaStats/DataFrames.jl/blob/master/src/dataframe.jl\n",
      "# \n",
      "# Also note that we need to use \"rename!\" to operate in place.\n",
      "for col_name in DataFrames.colnames(iris)\n",
      "    DataFrames.rename!(iris, col_name, replace(col_name, \"\\.\", \"_\"))\n",
      "end\n",
      "\n",
      "print(head(iris))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6x6 DataFrame:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          Sepal_Length Sepal_Width Petal_Length Petal_Width  Species\n",
        "[1,]    1          5.1         3.5          1.4         0.2 \"setosa\"\n",
        "[2,]    2          4.9         3.0          1.4         0.2 \"setosa\"\n",
        "[3,]    3          4.7         3.2          1.3         0.2 \"setosa\"\n",
        "[4,]    4          4.6         3.1          1.5         0.2 \"setosa\"\n",
        "[5,]    5          5.0         3.6          1.4         0.2 \"setosa\"\n",
        "[6,]    6          5.4         3.9          1.7         0.4 \"setosa\"\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Suppose we want to predict petal width as a function of sepal.length, sepal.width, and petal.length\n",
      "# for the \"setosa\" species.\n",
      "# data_set = iris[:(Species .== \"setosa\"), :][[\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]]\n",
      "mf = ModelFrame(Formula(:(Petal_Width ~ Sepal_Length + Sepal_Width + Petal_Length)),\n",
      "                iris[:(Species .== \"setosa\"), :])\n",
      "mm = ModelMatrix(mf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "ModelMatrix{Float64}(50x4 Array{Float64,2}:\n",
        " 1.0  5.1  3.5  1.4\n",
        " 1.0  4.9  3.0  1.4\n",
        " 1.0  4.7  3.2  1.3\n",
        " 1.0  4.6  3.1  1.5\n",
        " 1.0  5.0  3.6  1.4\n",
        " 1.0  5.4  3.9  1.7\n",
        " 1.0  4.6  3.4  1.4\n",
        " 1.0  5.0  3.4  1.5\n",
        " 1.0  4.4  2.9  1.4\n",
        " 1.0  4.9  3.1  1.5\n",
        " 1.0  5.4  3.7  1.5\n",
        " 1.0  4.8  3.4  1.6\n",
        " 1.0  4.8  3.0  1.4\n",
        " \u22ee                 \n",
        " 1.0  4.4  3.0  1.3\n",
        " 1.0  5.1  3.4  1.5\n",
        " 1.0  5.0  3.5  1.3\n",
        " 1.0  4.5  2.3  1.3\n",
        " 1.0  4.4  3.2  1.3\n",
        " 1.0  5.0  3.5  1.6\n",
        " 1.0  5.1  3.8  1.9\n",
        " 1.0  4.8  3.0  1.4\n",
        " 1.0  5.1  3.8  1.6\n",
        " 1.0  4.6  3.2  1.4\n",
        " 1.0  5.3  3.7  1.5\n",
        " 1.0  5.0  3.3  1.4,[0,1,2,3])"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Implementation\n",
      "So now we can implement a linear regression model using the dataframes structures explored above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using DataFrames\n",
      "using RDatasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Base.Test\n",
      "# Get some test dkata:\n",
      "iris_test = data(\"datasets\", \"iris\")\n",
      "for col_name in DataFrames.colnames(iris)\n",
      "    DataFrames.rename!(iris_test, col_name, replace(col_name, \"\\.\", \"_\"))\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parameters:\n",
      "#    training_data is a DataFrames.DataFrame (https://github.com/JuliaStats/DataFrames.jl/blob/master/src/dataframe.jl)\n",
      "#    containing the training data.\n",
      "#    \n",
      "#    reg_formula is a DataFrames.Formula (https://github.com/JuliaStats/DataFrames.jl/blob/master/src/formula.jl)\n",
      "#    specifying the linear equation to be fitted from training data.\n",
      "#\n",
      "# Example:\n",
      "# \n",
      "function linreg(training_data::DataFrame, reg_formula::Formula,\n",
      "                step_size::Float64, threshold::Float64, max_iter::Float64)\n",
      "    mf = ModelFrame(reg_formula, training_data)\n",
      "    mm = ModelMatrix(mf) # mm.m is the matrix data with constant-param 1 column added.\n",
      "    \n",
      "    # Size of training set\n",
      "    m = size(training_data,1)\n",
      "    # Number of features\n",
      "    n = size(mm, 2)\n",
      "    step_size = 0.08\n",
      "    theta = transpose(vector([1.0 for i=1:n]))\n",
      "    #print(theta)\n",
      "    # Hypothesis fcn: (theta_0' * mm.m[i,:])\n",
      "    # x_i vector: mm.m[i,:]\n",
      "    # y vector: model_response(mf)\n",
      "    iter_cnt = 0\n",
      "    diff = 1\n",
      "    while diff > threshold && iter_cnt < max_iter\n",
      "        grad = [(theta' * mm.m[i,:] - model_response(mf)[i])[1] * mm.m[i,:] for i=1:m]\n",
      "        theta1 = theta - (step_size/m)*sum(grad)\n",
      "        diff = sqrt(sum([x^2 for x in theta1 - theta]))\n",
      "        theta = theta1\n",
      "        \n",
      "        iter_cnt += 1\n",
      "        println(theta)\n",
      "        println(diff)\n",
      "    end\n",
      "end\n",
      "\n",
      "# 2D test on iris data:\n",
      "p = linreg(iris[:(Species .== \"setosa\"), :],\n",
      "           Formula(:(Petal_Width ~ Sepal_Length)),\n",
      "           0.2,\n",
      "           1e-5,\n",
      "           1e6)\n",
      "@test false\n",
      "\n",
      "# Plot result:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".93968\t.6988479999999999\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.3071335694840277\n",
        ".8841855999999999\t.4218529536\n",
        "\n",
        "0.2824993524974847\n",
        ".833130752\t.16708230451200007\n",
        "\n",
        "0.2598358734682798\n",
        ".78616029184\t-.06724189904895986\n",
        "\n",
        "0.2389854734123401\n",
        ".7429474684928\t-.2827553727250431\n",
        "\n",
        "0.21980310606897285\n",
        ".7031916710133761\t-.48096297490703976\n",
        "\n",
        "0.20215532888341486\n",
        ".666616337332306\t-.6632491753144767\n",
        "\n",
        "0.18591937471081887\n",
        ".6329670303457215\t-.8308876860893186\n",
        "\n",
        "0.17098229778396415\n",
        ".6020096679180638\t-.9850503224021732\n",
        "\n",
        "0.1572401880035979\n",
        ".5735288944846186\t-1.1268151542099993\n",
        "\n",
        "0.1445974480856024\n",
        ".5473265829258491\t-1.2571740058731995\n",
        "\n",
        "0.1329661285364474\n",
        ".5232204562917812\t-1.3770393558033436\n",
        "\n",
        "0.12226531583067053\n",
        ".5010428197884387\t-1.487250684139076\n",
        "\n",
        "0.11242056953423163\n",
        ".48063939420536356\t-1.5885803126079499\n",
        "\n",
        "0.10336340445807737\n",
        ".46186824266893445\t-1.681738777199314\n",
        "\n",
        "0.09503081423950879\n",
        ".4445987832554197\t-1.767379771023369\n",
        "\n",
        "0.0873648330371372\n",
        ".42871088059498613\t-1.8461046917414994\n",
        "\n",
        "0.08031213229035407\n",
        ".4140940101473872\t-1.9184668252021795\n",
        "\n",
        "0.07382364973816433\n",
        ".40064648933559627\t-1.984975194386005\n",
        "\n",
        "0.06785424811664766\n",
        ".38827477018874856\t-2.0460981004351244\n",
        "\n",
        "0.06236240116077921\n",
        ".37689278857364866\t-2.1022663804003145\n",
        "\n",
        "0.05730990472627268\n",
        ".3664213654877568\t-2.1538764043682894\n",
        "\n",
        "0.05266161102186953\n",
        ".3567876562487362\t-2.2012928328188264\n",
        "\n",
        "0.04838518410326533\n",
        ".3479246437488373\t-2.2448511533933204\n",
        "\n",
        "0.04445087492776442\n",
        ".3397706722489303\t-2.284860014721855\n",
        "\n",
        "0.04083131440484376\n",
        ".3322690184690159\t-2.3216033735441064\n",
        "\n",
        "0.03750132300298786\n",
        ".32536749699149464\t-2.355342470060578\n",
        "\n",
        "0.03443773558834064\n",
        ".31901809723217506\t-2.3863176452557315\n",
        "\n",
        "0.031619240276675085\n",
        ".3131766494536011\t-2.414750012835273\n",
        "\n",
        "0.029026230177685297\n",
        ".30780251749731297\t-2.4408429974084513\n",
        "\n",
        "0.026640667000278336\n",
        ".30285831609752795\t-2.4647837496157754\n",
        "\n",
        "0.02444595557007596\n",
        ".2983096508097257\t-2.4867444480465135\n",
        "\n",
        "0.02242682838624937\n",
        ".29412487874494764\t-2.5068834970027924\n",
        "\n",
        "0.020569239414658644\n",
        ".2902748884453518\t-2.525346628442569\n",
        "\n",
        "0.01886026637853893\n",
        ".2867328973697237\t-2.5422679157671633\n",
        "\n",
        "0.017288020867100583\n",
        ".28347426558014577\t-2.5577707065057904\n",
        "\n",
        "0.01584156563682111\n",
        ".2804763243337341\t-2.571968480385327\n",
        "\n",
        "0.014510838530263876\n",
        ".27771821838703536\t-2.584965638754501\n",
        "\n",
        "0.013286582483339983\n",
        ".2751807609160725\t-2.596858230854141\n",
        "\n",
        "0.012160281134306264\n",
        ".2728463000427867\t-2.6077346219858097\n",
        "\n",
        "0.011124099586840686\n",
        ".27069859603936375\t-2.617676108226945\n",
        "\n",
        "0.010170829915449483\n",
        ".26872270835621465\t-2.6267574819687893\n",
        "\n",
        "0.009293841034549638\n",
        ".26690489168771747\t-2.635047552211286\n",
        "\n",
        "0.008487032583052674\n",
        ".2652325003527001\t-2.6426096232343834\n",
        "\n",
        "0.007744792504374043\n",
        ".2636939003244841\t-2.649501934975633\n",
        "\n",
        "0.007061958027727883\n",
        ".26227838829852534\t-2.655778068177582\n",
        "\n",
        "0.00643377978052116\n",
        ".2609761172346433\t-2.6614873171233753\n",
        "\n",
        "0.005855888783853915\n",
        ".25977802785587184\t-2.6666750325535054\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.005324266103749392\n",
        ".2586757856274021\t-2.671382937149225\n",
        "\n",
        "0.004835214949991189\n",
        ".25766172277720994\t-2.6756494157772868\n",
        "\n",
        "0.0043853350325658465\n",
        ".25672878495503315\t-2.6795097825151037\n",
        "\n",
        "0.003971499002957407\n",
        ".2558704821586305\t-2.6829965263138953\n",
        "\n",
        "0.0035908308242973393\n",
        ".2550808435859401\t-2.6861395370087835\n",
        "\n",
        "0.0032406859310433363\n",
        ".25435437609906486\t-2.6889663132480806\n",
        "\n",
        "0.00291863305616537\n",
        ".25368602601113965\t-2.691502153788234\n",
        "\n",
        "0.0026224376227310517\n",
        ".2530711439302485\t-2.6937703334851753\n",
        "\n",
        "0.0023500466189030405\n",
        ".2525054524158286\t-2.6957922652063613\n",
        "\n",
        "0.0020995749033137544\n",
        ".2519850162225623\t-2.6975876487898525\n",
        "\n",
        "0.001869292925983289\n",
        ".25150621492475733\t-2.6991746080866643\n",
        "\n",
        "0.001657615906209064\n",
        ".25106571773077674\t-2.700569817039731\n",
        "\n",
        "0.0014630945972912237\n",
        ".2506604603123146\t-2.7017886156765525\n",
        "\n",
        "0.0012844079150861774\n",
        ".2502876234873294\t-2.702845116822428\n",
        "\n",
        "0.0011203579648047998\n",
        ".24994461360834305\t-2.703752304276634\n",
        "\n",
        "0.0009698684726036132\n"
       ]
      },
      {
       "ename": "LoadError",
       "evalue": "test failed: false\nat In[275]:45",
       "output_type": "pyerr",
       "traceback": [
        "test failed: false\nat In[275]:45",
        " in error at error.jl:21",
        " in default_handler at test.jl:21",
        " in do_test at test.jl:38"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 2D test on iris data:\n",
      "p = linreg(iris[:(Species .== \"setosa\"), :],\n",
      "           Formula(:(Petal_Width ~ Sepal_Length)))\n",
      "@test false\n",
      "\n",
      "# Plot result:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n"
       ]
      },
      {
       "ename": "LoadError",
       "evalue": "test failed: false\nat In[98]:4",
       "output_type": "pyerr",
       "traceback": [
        "test failed: false\nat In[98]:4",
        " in error at error.jl:21",
        " in default_handler at test.jl:21",
        " in do_test at test.jl:38"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unit/Functional Tests:<br>\n",
      "\n",
      "http://docs.julialang.org/en/latest/stdlib/test/?highlight=test#Base.Test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 4D test on iris data:\n",
      "#Formula(:(Petal_Width ~ Sepal_Length + Sepal_Width + Petal_Length)), iris[:(Species .== \"setosa\"), :]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}