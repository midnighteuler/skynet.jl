{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Describing and implementing multivariate linear regression.<br><br>\n",
      "Definitions:<br>\n",
      "Let the set of $m$ training examples be $T = \\{(\\vec{x_{i}}, y_i)\\}$ for $0 \\leq i \\leq m - 1$<br>\n",
      "where $\\vec{x_{i}} \\in \\mathbb{R}^n$ is the $i^\\text{th}$ training example input, and $n$ is the number of features, $y_i \\in \\mathbb{R}$ is $i^\\text{th}$ is the training output.<br>\n",
      "Let $x_{i,j}$ denote the $j^\\text{th}$ feature of the $i^\\text{th}$ training example.<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The linear regression hypothesis function $h_\\vec{\\theta} : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ has form:<br>\n",
      "$$h_\\vec{\\theta}(\\vec{x}) = \\sum_{i=0}^{n} \\theta_{i} x_{i} = \\vec{\\theta}^{T} \\vec{x}$$\n",
      "Where we take $x_0 = 1$, and let $\\vec{\\theta} \\in \\mathbb{R}^{n+1}$ be the parameter vector.<br>\n",
      "<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The cost function $J : \\mathbb{R}^{n+1} \\rightarrow \\mathbb{R}$ has form:<br>\n",
      "$$J(\\vec{\\theta}) = \\frac{1}{2 m}\\sum_{i=1}^{m}(h_\\vec{\\theta}(\\vec{x}_{i}) - y_i)^2 = \\frac{1}{2 m}\\sum_{i=1}^{m}(\\vec{\\theta}^{T} \\vec{x} - y_i)^2$$<br>\n",
      "\n",
      "We want to minimize the cost function $J$ by varying the parameter vector $\\vec{\\theta}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, we can analytically solve this problem by solving the system of equations for $(\\theta_0, \\theta_1, \\dotsc, \\theta_{n})^T$ given by $\\frac{\\partial}{\\partial \\theta_i}{J(\\vec{\\theta})} = 0$ for all $i \\in \\{0,1,...,n\\}$.<br>\n",
      "\n",
      "\n",
      "We can alternatively use an optimization algorithm like gradient descent, and we can recycle it for other min/max problems; so I'll go over that."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Gradient Descent"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One method to find the parameter vector is the gradient descent algorithm.<br><br>\n",
      "\n",
      "The idea in gradient descent is similar to the idea in single variable calculus:<br>\n",
      "<img src=\"files/images/deriv.png\"><br>\n",
      "Where we know that $\\frac{d}{dx} f(x) = 0$ at the extrema (points A and B), and $\\frac{d}{dx} f(x)$ can otherwise be used direct us toward the nearest (local) minimum/maximum (e.g. the slope of the lines at points C, D, E, F).<br><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a multivariate function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$, we use the vector differential, or gradient: $\\vec{\\nabla} f(x)$ to guide us to a minimum.<br>For example, in:\n",
      "<img src=\"files/images/gradient.png\" width=\"400px\"><br>\n",
      "A gradient vector field is shown projected beneath a plot of the function $f(x,y) = \u2212(\\cos^2 x + \\cos^2 y)^2.$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the vectors are pointed to the direction of maximum ascent--i.e. away from the minimum, thus if we want to minimize our cost function $J$ in the linear regression problem, we need to look toward the opposite direction: $-\\vec{\\nabla} f(x)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see how we actually follow that direction, consider the Taylor expansion of $f(\\vec{x}_0 + h\\vec{\\epsilon})$ where $\\epsilon \\in \\mathbb{R}^{n+1}$ is a unit-vector that we want to minimize in the direction of if we start at vector $\\vec{x}_0$, and $h \\in \\mathbb{R}$ is a constant \"step-size\":<br>\n",
      "$$\n",
      "f(\\vec{x}_0 + h\\vec{\\epsilon}) = f(\\vec{x}_0) + h\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon} + h^2\\text{(const. error)}\n",
      "$$\n",
      "<br><br>\n",
      "If we take $h$ to be very small such that $h^2$ is even smaller, then let's regard $h^2\\text{(const. error)} \\approx 0$ so that:\n",
      "$$\n",
      "f(\\vec{x}_0 + h\\vec{\\epsilon}) \\approx f(\\vec{x}_0) + h\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to choose a vector $\\vec{\\epsilon}$ that minimizes $f(\\vec{x}_0 + h\\vec{\\epsilon})$.<br>\n",
      "i.e. that minimizes\n",
      "$f(\\vec{x}_0) + h\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon}$.<br><br>\n",
      "\n",
      "Note that $\\vec{\\nabla} f(\\vec{x}_0) \\cdot \\vec{\\epsilon} = \\lvert \\vec{\\nabla} f(\\vec{x}_0) \\rvert \\lvert \\vec{\\epsilon} \\rvert \\cos \\delta$ where $\\delta$ is the angle between $\\vec{\\nabla} f(\\vec{x}_0)$ and $\\vec{\\epsilon}$.<br>\n",
      "By choosing unit-vector $\\vec{\\epsilon} = \\frac{-\\vec{\\nabla} f(\\vec{x}_0)}{\\lvert \\vec{\\nabla} f(\\vec{x}_0) \\rvert}$, we have $\\cos(\\delta) = -1$, its least value. <br><br>\n",
      "\n",
      "So taking:\n",
      "$\\vec{x_1} = \\vec{x}_0 + h\\vec{\\epsilon} = \\vec{x}_0 - h\\vec{\\nabla} f(\\vec{x}_0)$ for some step-size $h$,<br>\n",
      "and inspecting whether $f(\\vec{x_{i+1}}) - f(\\vec{x_{i}})$ reaches convergence within some threshold, we have the basic gradient descent algorithm.<br><br>\n",
      "\n",
      "To implement it with our cost function, we need the $i^\\text{th}$ component of $\\vec{\\nabla}J(\\vec{\\theta})$.<br>\n",
      "This is given by:  $\\frac{\\partial}{\\partial \\theta_i} J(\\vec{\\theta}) = \\frac{1}{m} \\sum_{j=1}^{m}x_{j,i}(\\vec{\\theta}^T \\cdot \\vec{x}_j - y_j)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also see: http://mathworld.wolfram.com/MethodofSteepestDescent.html <br>\n",
      "\n",
      "Image sources:<br>\n",
      "http://www.themathpage.com/acalc/calc_IMG/060.png<br>\n",
      "http://en.wikipedia.org/wiki/File:Gradient99.png<br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Metaprogramming and DataFrames Formulas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Julia has \"metaprogramming\" support: http://docs.julialang.org/en/latest/manual/metaprogramming/<br>\n",
      "\n",
      "The DataFrames package provides a \"Formula\" object for use in regression modeling: <a href=\"https://github.com/JuliaStats/DataFrames.jl/blob/f9556c023db999db39f85261698d5edde4089159/doc/sections/09_formulas.md\">DataFrames.Formula</a><br>\n",
      "\n",
      "Although not explicitly stated (outside the development mailing list?), the syntax of formulae seems similar to that of <a href=\"http://science.nature.nps.gov/im/datamgmt/statistics/r/formulas/\">R formulae</a>, which is in turn derived from the \"S\" language:<br>\n",
      "<p>\n",
      "<b>Chambers and Hastie (1993) \"Statistical Models in S\" is the definitive reference for formulas in S and thus R, although their conception of formulas has been extended for other uses, and there is a package \"formula\" that defines a new object class Formula that inherits from class formula. At the R command line, ?formula will give you some details.</b><br>\n",
      "\n",
      "But more practically, we can just look at the source: https://github.com/JuliaStats/DataFrames.jl/blob/master/src/formula.jl"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using DataFrames\n",
      "using RDatasets\n",
      "\n",
      "iris = data(\"datasets\", \"iris\")\n",
      "# The DataFrames formula parser seems to take issue with column names having periods\n",
      "# and I don't know if there's some proper way to escape them--so I'll just rename them:\n",
      "# Uses string.replace: https://github.com/JuliaLang/julia/blob/master/base/string.jl\n",
      "# and dataframe.rename: https://github.com/JuliaStats/DataFrames.jl/blob/master/src/dataframe.jl\n",
      "# \n",
      "# Also note that we need to use \"rename!\" to operate in place.\n",
      "for col_name in DataFrames.colnames(iris)\n",
      "    DataFrames.rename!(iris, col_name, replace(col_name, \"\\.\", \"_\"))\n",
      "end\n",
      "\n",
      "print(head(iris))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6x6 DataFrame:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          Sepal_Length Sepal_Width Petal_Length Petal_Width  Species\n",
        "[1,]    1          5.1         3.5          1.4         0.2 \"setosa\"\n",
        "[2,]    2          4.9         3.0          1.4         0.2 \"setosa\"\n",
        "[3,]    3          4.7         3.2          1.3         0.2 \"setosa\"\n",
        "[4,]    4          4.6         3.1          1.5         0.2 \"setosa\"\n",
        "[5,]    5          5.0         3.6          1.4         0.2 \"setosa\"\n",
        "[6,]    6          5.4         3.9          1.7         0.4 \"setosa\"\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Suppose we want to predict petal width as a function of sepal.length, sepal.width, and petal.length\n",
      "# for the \"setosa\" species.\n",
      "# data_set = iris[:(Species .== \"setosa\"), :][[\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]]\n",
      "mf = ModelFrame(Formula(:(Petal_Width ~ Sepal_Length + Sepal_Width + Petal_Length)),\n",
      "                iris[:(Species .== \"setosa\"), :])\n",
      "mm = ModelMatrix(mf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 68,
       "text": [
        "ModelMatrix{Float64}(50x4 Array{Float64,2}:\n",
        " 1.0  5.1  3.5  1.4\n",
        " 1.0  4.9  3.0  1.4\n",
        " 1.0  4.7  3.2  1.3\n",
        " 1.0  4.6  3.1  1.5\n",
        " 1.0  5.0  3.6  1.4\n",
        " 1.0  5.4  3.9  1.7\n",
        " 1.0  4.6  3.4  1.4\n",
        " 1.0  5.0  3.4  1.5\n",
        " 1.0  4.4  2.9  1.4\n",
        " 1.0  4.9  3.1  1.5\n",
        " 1.0  5.4  3.7  1.5\n",
        " 1.0  4.8  3.4  1.6\n",
        " 1.0  4.8  3.0  1.4\n",
        " \u22ee                 \n",
        " 1.0  4.4  3.0  1.3\n",
        " 1.0  5.1  3.4  1.5\n",
        " 1.0  5.0  3.5  1.3\n",
        " 1.0  4.5  2.3  1.3\n",
        " 1.0  4.4  3.2  1.3\n",
        " 1.0  5.0  3.5  1.6\n",
        " 1.0  5.1  3.8  1.9\n",
        " 1.0  4.8  3.0  1.4\n",
        " 1.0  5.1  3.8  1.6\n",
        " 1.0  4.6  3.2  1.4\n",
        " 1.0  5.3  3.7  1.5\n",
        " 1.0  5.0  3.3  1.4,[0,1,2,3])"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Implementation\n",
      "So now we can implement a linear regression model using the dataframes structures explored above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parameters:\n",
      "#    training_data is a DataFrames.DataFrame (https://github.com/JuliaStats/DataFrames.jl/blob/master/src/dataframe.jl)\n",
      "#    containing the training data.\n",
      "#    \n",
      "#    reg_formula is a DataFrames.Formula (https://github.com/JuliaStats/DataFrames.jl/blob/master/src/formula.jl)\n",
      "#    specifying the linear equation to be fitted from training data.\n",
      "#\n",
      "# Example:\n",
      "# \n",
      "function linreg(training_data::DataFrame, reg_formula::Formula)\n",
      "    \n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unit Tests:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}